# FASE 1: ExtracciÃ³n de Datos de Polymarket API

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa la **Fase 1** del ecosistema de datos sobre Polymarket, que consiste en la extracciÃ³n automatizada de datos desde los endpoints pÃºblicos de la API de Polymarket.

## ğŸ¯ Objetivos de la Fase 1

La Fase 1 se enfoca en la **recolecciÃ³n y almacenamiento de datos brutos** desde la API de Polymarket, extrayendo informaciÃ³n de los siguientes endpoints:

- **Tags** ğŸ·ï¸: Etiquetas utilizadas para categorizar eventos y mercados
- **Events** ğŸ“…: Eventos de predicciÃ³n disponibles en la plataforma
- **Series** ğŸ“Š: Series de eventos relacionados
- **Markets** ğŸ’¹: Mercados de predicciÃ³n individuales

## ğŸ—ï¸ Arquitectura del Sistema

```
fase1_extraccion/
â”‚
â”œâ”€â”€ config.py                 # ConfiguraciÃ³n central del sistema
â”œâ”€â”€ delta_utils.py            # Utilidades para Delta Lake
â”œâ”€â”€ extract_tags.py           # Extractor de Tags
â”œâ”€â”€ extract_events.py         # Extractor de Events
â”œâ”€â”€ extract_series.py         # Extractor de Series
â”œâ”€â”€ extract_markets.py        # Extractor de Markets
â”œâ”€â”€ main.py                   # Script orquestador principal
â”œâ”€â”€ check_delta.py            # Script de verificaciÃ³n Delta Lake
â”œâ”€â”€ requirements.txt          # Dependencias del proyecto
â”‚
â”œâ”€â”€ delta_lake/               # â­ Directorio para tablas Delta Lake
â”‚   â”œâ”€â”€ tags/
â”‚   â”‚   â”œâ”€â”€ part-*.snappy.parquet
â”‚   â”‚   â””â”€â”€ _delta_log/
â”‚   â”œâ”€â”€ events/
â”‚   â”‚   â”œâ”€â”€ part-*.snappy.parquet
â”‚   â”‚   â””â”€â”€ _delta_log/
â”‚   â”œâ”€â”€ series/
â”‚   â”‚   â”œâ”€â”€ part-*.snappy.parquet
â”‚   â”‚   â””â”€â”€ _delta_log/
â”‚   â””â”€â”€ markets/
â”‚       â”œâ”€â”€ part-*.snappy.parquet
â”‚       â””â”€â”€ _delta_log/
â”‚
â””â”€â”€ logs/                     # Directorio para logs de ejecuciÃ³n
    â”œâ”€â”€ delta_lake_YYYYMMDD.log
    â”œâ”€â”€ tags_extractor_YYYYMMDD.log
    â”œâ”€â”€ events_extractor_YYYYMMDD.log
    â”œâ”€â”€ series_extractor_YYYYMMDD.log
    â”œâ”€â”€ markets_extractor_YYYYMMDD.log
    â””â”€â”€ main_extraction_YYYYMMDD_HHMMSS.log
```

## ğŸ“¡ Endpoints de la API Polymarket

| Endpoint | URL | DescripciÃ³n |
|----------|-----|-------------|
| **Tags** | `https://gamma-api.polymarket.com/tags` | Obtiene todas las etiquetas disponibles |
| **Events** | `https://gamma-api.polymarket.com/events` | Obtiene todos los eventos de predicciÃ³n |
| **Series** | `https://gamma-api.polymarket.com/series` | Obtiene todas las series de eventos |
| **Markets** | `https://gamma-api.polymarket.com/markets` | Obtiene todos los mercados de predicciÃ³n |

## ï¿½ Formato de Almacenamiento: Delta Lake

El sistema utiliza **Delta Lake** como formato de almacenamiento principal, proporcionando:

### CaracterÃ­sticas de Delta Lake

- **ğŸ“¦ Formato Parquet + Snappy**: CompresiÃ³n eficiente (reducciÃ³n de ~95% vs JSON)
- **ğŸ”’ Transacciones ACID**: GarantÃ­a de consistencia de datos
- **ğŸ“œ Versionamiento**: Historial completo de cambios con "time travel"
- **ğŸ”„ Schema Evolution**: Capacidad de modificar esquemas sin reescribir datos
- **âš¡ Performance**: Lectura columnar y predicado pushdown

### ComparaciÃ³n de TamaÃ±os

| Tabla    | Formato Delta | Formato JSON | ReducciÃ³n |
|----------|---------------|--------------|-----------|
| Tags     | 0.03 MB       | 0.13 MB      | 77%       |
| Events   | 0.88 MB       | 4.09 MB      | 78%       |
| Markets  | 0.75 MB       | 3.64 MB      | 79%       |
| Series   | 17.65 MB      | 424.29 MB    | **96%**   |
| **TOTAL**| **19.31 MB**  | **432.15 MB**| **95.5%** |

### Estructura de Tabla Delta

Cada tabla Delta contiene:
- `part-*.snappy.parquet`: Archivos de datos en formato Parquet
- `_delta_log/`: Log de transacciones con metadatos y versiones

## ï¿½ğŸ”§ CaracterÃ­sticas TÃ©cnicas

### Funcionalidades Implementadas

âœ… **ExtracciÃ³n por paginaciÃ³n**: Manejo automÃ¡tico de lÃ­mites y offsets
âœ… **Logging completo**: Registro detallado de todas las operaciones
âœ… **Manejo de errores**: Captura y registro de excepciones
âœ… **ConfiguraciÃ³n centralizada**: ParÃ¡metros ajustables desde `config.py`
âœ… **Almacenamiento Delta Lake**: Formato empresarial con ACID, versionamiento y compresiÃ³n
âœ… **EjecuciÃ³n modular**: Cada endpoint puede ejecutarse independientemente
âœ… **Script orquestador**: AutomatizaciÃ³n de todas las extracciones
âœ… **Metadatos de extracciÃ³n**: Timestamp y fecha agregados automÃ¡ticamente

### ParÃ¡metros Configurables

En el archivo `config.py` puedes ajustar:

- **limit**: NÃºmero de registros por peticiÃ³n (default: 500 - aumentado para eficiencia)
- **offset**: Offset inicial para paginaciÃ³n (default: 0)
- **max_records**: MÃ¡ximo de registros a extraer (default: 0 = **SIN LÃMITE**, extrae todos los datos)
- **REQUEST_TIMEOUT**: Timeout de las peticiones HTTP (default: 30s)

> **IMPORTANTE**: Para extraer TODOS los datos disponibles, asegÃºrate de que `max_records = 0` en `config.py`

## ğŸš€ InstalaciÃ³n y Uso

### Prerrequisitos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### Dependencias Principales

- `requests==2.31.0` - Cliente HTTP para API calls
- `deltalake==0.19.0` - Formato Delta Lake
- `pandas==2.2.0` - ManipulaciÃ³n de datos
- `pyarrow==16.1.0` - Backend columnar para Parquet

### InstalaciÃ³n

1. Navega al directorio del proyecto:
```bash
cd "e:\Clases\Materias\Erick Venezolano (5074)\PROYECTO RA-2\fase1_extraccion"
```

2. Instala las dependencias:
```bash
pip install -r requirements.txt
```

### EjecuciÃ³n

#### OpciÃ³n 1: â­ EXTRACCIÃ“N COMPLETA SIN LÃMITES (Recomendado)

Para extraer **TODOS** los datos disponibles de la API sin lÃ­mites:

**Usando el script dedicado:**
```bash
python extraer_completo.py
```

**O usando el archivo batch (Windows):**
```bash
extraer_completo.bat
```

**O usando el notebook interactivo:**
- Abre `extraer_datos_delta_lake.ipynb`
- Ve a la secciÃ³n "2.5. RE-EXTRAER TODOS LOS DATOS DE LA API (SIN LÃMITES)"
- Ejecuta las celdas de extracciÃ³n

Este comando:
- âœ… Extrae **TODOS** los registros disponibles (sin lÃ­mite de 500)
- âœ… Utiliza paginaciÃ³n automÃ¡tica (500 registros por peticiÃ³n)
- âœ… Guarda los datos en Delta Lake con compresiÃ³n
- âœ… Muestra progreso en tiempo real
- âœ… Genera logs detallados de la extracciÃ³n

**ConfiguraciÃ³n actual** (en `config.py`):
- `limit`: 500 (registros por peticiÃ³n)
- `max_records`: 0 (sin lÃ­mite = extrae todo)

#### OpciÃ³n 2: Ejecutar extracciÃ³n con lÃ­mite (Modo legacy)

```bash
python main.py
```

Este comando ejecutarÃ¡ la extracciÃ³n usando la configuraciÃ³n de `max_records` en `config.py`.

#### OpciÃ³n 3: Ejecutar extractores individuales

Puedes ejecutar cada extractor de forma independiente:

```bash
# Extraer solo Tags
python extract_tags.py

# Extraer solo Events
python extract_events.py

# Extraer solo Series
python extract_series.py

# Extraer solo Markets
python extract_markets.py
```

#### OpciÃ³n 4: Verificar Tablas Delta Lake

Para ver informaciÃ³n detallada sobre las tablas Delta Lake generadas:

```bash
python check_delta.py
```

Este script muestra:
- VersiÃ³n actual de cada tabla
- NÃºmero de archivos y tamaÃ±o total
- NÃºmero de registros y columnas
- ComparaciÃ³n con archivos JSON legacy

### Trabajar con Tablas Delta Lake

```python
from delta_utils import DeltaLakeManager

# Inicializar gestor
manager = DeltaLakeManager()

# Leer tabla completa
df = manager.read_delta_table("tags")

# Leer versiÃ³n especÃ­fica (time travel)
df_v0 = manager.read_delta_table("tags", version=0)

# Obtener informaciÃ³n de tabla
info = manager.get_table_info("tags")
print(f"VersiÃ³n: {info['version']}")

# Listar todas las tablas
tables = manager.list_tables()
print(tables)  # ['events', 'markets', 'series', 'tags']
```

## âš¡ Probar API con Thunder Client

Thunder Client es una extensiÃ³n de VS Code que permite probar la API de Polymarket de forma visual sin escribir cÃ³digo.

### InstalaciÃ³n RÃ¡pida

1. En VS Code: `Ctrl+Shift+X`
2. Buscar: "Thunder Client"
3. Click en "Install"
4. Click en el Ã­cono del rayo âš¡ en la barra lateral

### Importar ColecciÃ³n Pre-configurada

Hemos incluido una colecciÃ³n con **15 requests pre-configuradas** listas para usar:

```
1. Abre Thunder Client (âš¡)
2. Ve a "Collections"
3. Click en el menÃº â‹® â†’ "Import"
4. Selecciona: thunder-collection_polymarket.json
5. Â¡Listo! Ya puedes probar la API
```

### Requests Disponibles

La colecciÃ³n incluye:

- **Tags** (3 requests): Listar, paginaciÃ³n, obtener cantidades variables
- **Events** (5 requests): Todos, activos, featured, alta liquidez, por tag
- **Series** (3 requests): Todas, activas, featured
- **Markets** (4 requests): Todos, activos, alta liquidez, top volume

### Ejemplo RÃ¡pido

```
1. Expande la carpeta "Tags"
2. Click en "Tags - Listar Todos (10 primeros)"
3. Click en "Send" (botÃ³n azul)
4. Â¡Ver respuesta JSON!
```

### DocumentaciÃ³n Completa

- **[THUNDER_CLIENT_QUICKSTART.md](THUNDER_CLIENT_QUICKSTART.md)** - GuÃ­a visual paso a paso
- **[THUNDER_CLIENT_GUIA.md](THUNDER_CLIENT_GUIA.md)** - GuÃ­a completa con todos los parÃ¡metros

### Beneficios

âœ… **Sin cÃ³digo**: Prueba la API visualmente
âœ… **RÃ¡pido**: Click y enviar, ver resultados inmediatos
âœ… **Aprendizaje**: Entiende cÃ³mo funcionan los endpoints
âœ… **Debugging**: Compara datos API vs Delta Lake
âœ… **ExploraciÃ³n**: Descubre nuevos parÃ¡metros y filtros

## ğŸ“Š Estructura de Datos ExtraÃ­dos

### Tags
```json
[
  {
    "id": "string",
    "label": "string",
    "slug": "string",
    "forceShow": boolean,
    "publishedAt": "string",
    "createdBy": integer,
    "updatedBy": integer,
    "createdAt": "datetime",
    "updatedAt": "datetime",
    "forceHide": boolean,
    "isCarousel": boolean
  }
]
```

### Events
Los eventos contienen informaciÃ³n detallada incluyendo:
- InformaciÃ³n bÃ¡sica (id, tÃ­tulo, descripciÃ³n, slug)
- Fechas (startDate, endDate, creationDate)
- MÃ©tricas (liquidity, volume, openInterest)
- Relaciones (markets, series, tags, categories)
- Estado (active, closed, archived, featured)

### Series
Las series agrupan eventos relacionados con informaciÃ³n sobre:
- Tipo de serie (seriesType, recurrence)
- MÃ©tricas agregadas (volume, liquidity)
- Eventos asociados
- CategorÃ­as y tags

### Markets
Los mercados contienen informaciÃ³n completa sobre:
- Pregunta y descripciÃ³n
- Resultados posibles (outcomes, outcomePrices)
- MÃ©tricas de trading (volume, liquidity, spread)
- ConfiguraciÃ³n del mercado (fees, limits)
- Estado de resoluciÃ³n

## ğŸ“ˆ Salida del Sistema

### Tablas Delta Lake Generadas

Cada ejecuciÃ³n crea/actualiza tablas Delta Lake en el directorio `delta_lake/`:

```
delta_lake/
â”œâ”€â”€ tags/
â”‚   â”œâ”€â”€ part-00001-*.snappy.parquet    # Datos en Parquet comprimido
â”‚   â””â”€â”€ _delta_log/
â”‚       â””â”€â”€ 00000000000000000000.json  # Log de transacciones
â”œâ”€â”€ events/
â”‚   â”œâ”€â”€ part-00001-*.snappy.parquet
â”‚   â””â”€â”€ _delta_log/
â”œâ”€â”€ series/
â”‚   â”œâ”€â”€ part-00001-*.snappy.parquet
â”‚   â””â”€â”€ _delta_log/
â””â”€â”€ markets/
    â”œâ”€â”€ part-00001-*.snappy.parquet
    â””â”€â”€ _delta_log/
```

**Beneficios del formato Delta:**
- CompresiÃ³n superior (~95% reducciÃ³n vs JSON)
- Versionamiento automÃ¡tico
- Transacciones ACID
- Lectura columnar eficiente

### Logs de EjecuciÃ³n

Los logs se almacenan en el directorio `logs/` con informaciÃ³n detallada:

```
logs/
â”œâ”€â”€ tags_extractor_20260210.log
â”œâ”€â”€ events_extractor_20260210.log
â”œâ”€â”€ series_extractor_20260210.log
â”œâ”€â”€ markets_extractor_20260210.log
â””â”€â”€ main_extraction_20260210_143052.log
```

## ğŸ¨ Ejemplo de Salida en Consola

```
============================================================
 POLYMARKET DATA EXTRACTOR - FASE 1 
============================================================

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         FASE 1: EXTRACCIÃ“N DE DATOS DE POLYMARKET        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

============================================================
Iniciando extracciÃ³n de TAGS
============================================================
INFO - Tags extraÃ­dos exitosamente: 150 registros
âœ“ Tags extraÃ­dos: 150 registros

============================================================
Iniciando extracciÃ³n de EVENTS
============================================================
INFO - Events extraÃ­dos exitosamente: 500 registros
âœ“ Events extraÃ­dos: 500 registros

============================================================
Iniciando extracciÃ³n de SERIES
============================================================
INFO - Series extraÃ­das exitosamente: 75 registros
âœ“ Series extraÃ­das: 75 registros

============================================================
Iniciando extracciÃ³n de MARKETS
============================================================
INFO - Markets extraÃ­dos exitosamente: 500 registros
âœ“ Markets extraÃ­dos: 500 registros

============================================================
RESUMEN DE EXTRACCIÃ“N
============================================================
TAGS            - âœ“ Exitoso   - 150 registros
EVENTS          - âœ“ Exitoso   - 500 registros
SERIES          - âœ“ Exitoso   - 75 registros
MARKETS         - âœ“ Exitoso   - 500 registros
============================================================
Tiempo total de ejecuciÃ³n: 0:02:15.123456
============================================================

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              RESUMEN FINAL DE EXTRACCIÃ“N                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  TAGS         :    150 registros extraÃ­dos              â•‘
â•‘  EVENTS       :    500 registros extraÃ­dos              â•‘
â•‘  SERIES       :     75 registros extraÃ­dos              â•‘
â•‘  MARKETS      :    500 registros extraÃ­dos              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ Todas las extracciones se completaron exitosamente
```

## ğŸ” VerificaciÃ³n de Datos

Para verificar que los datos se extrajeron correctamente:

```python
from delta_utils import DeltaLakeManager

# Inicializar gestor de Delta Lake
manager = DeltaLakeManager()

# Leer tabla de tags
tags_df = manager.read_delta_table("tags")
print(f"Total de tags: {len(tags_df)}")
print(f"Columnas: {tags_df.columns.tolist()}")
print(f"\nPrimeros 5 registros:")
print(tags_df.head())

# Obtener informaciÃ³n de la tabla
info = manager.get_table_info("tags")
print(f"\nVersiÃ³n de la tabla: {info['version']}")
```
```

## âš ï¸ Manejo de Errores

El sistema incluye manejo robusto de errores:

- **Timeout de conexiÃ³n**: Configurable en `config.py`
- **Errores HTTP**: Se registran con cÃ³digo de estado
- **Errores de parsing**: Se capturan y registran
- **Interrupciones**: El usuario puede detener con Ctrl+C

## ğŸ“ PrÃ³ximos Pasos (Fases Futuras)

- **Fase 2**: TransformaciÃ³n y limpieza de datos
- **Fase 3**: Carga en Data Lake
- **Fase 4**: Modelado dimensional para Data Warehouse
- **Fase 5**: AnÃ¡lisis y visualizaciÃ³n

## ğŸ‘¥ Autor

Proyecto RA-2: Ecosistema de Datos (Datalake & Datawarehouse)
Materia: Erick Venezolano (5074)

## ğŸ“„ Licencia

Este proyecto es con fines educativos.

## ğŸ”— Referencias

- [DocumentaciÃ³n API Polymarket](https://docs.polymarket.com/)
- [Polymarket GitHub](https://github.com/polymarket)

---

**Fecha de CreaciÃ³n**: Febrero 10, 2026  
**VersiÃ³n**: 1.0.0  
**Estado**: Fase 1 Completa âœ…
