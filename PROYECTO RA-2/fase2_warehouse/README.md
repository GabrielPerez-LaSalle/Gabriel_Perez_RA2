# ============================================================
# FASE 2: DATA WAREHOUSE EN NEONDB (CAPA GOLD)
# ============================================================

Este directorio contiene todos los scripts necesarios para implementar la Fase 2 del proyecto: 
el Data Warehouse en NeonDB con modelado dimensional optimizado para an√°lisis.

## üìã Contenido

- `schema_ddl.sql` - Script SQL con el DDL completo del esquema dimensional
- `neondb_config.py` - Configuraci√≥n de conexi√≥n a NeonDB
- `create_schema.py` - Script para crear las tablas en NeonDB
- `etl_warehouse.py` - ETL completo: Delta Lake ‚Üí NeonDB
- `README.md` - Esta documentaci√≥n

## üèóÔ∏è Arquitectura del Data Warehouse

### Modelo Dimensional (Star Schema)

El Data Warehouse implementa un **esquema en estrella** con las siguientes componentes:

#### Dimensiones:

1. **dim_time** - Dimensi√≥n de tiempo
   - Granularidad: Diaria
   - Atributos: a√±o, trimestre, mes, semana, d√≠a, indicadores de per√≠odo
   - Rango: 2021-01-01 a 2026-12-31

2. **dim_series** - Dimensi√≥n de series de mercados
   - Series como: NBA, Elections, Crypto, etc.
   - Tipo: SCD Type 2 (Slowly Changing Dimension)

3. **dim_event** - Dimensi√≥n de eventos
   - Eventos que contienen m√∫ltiples mercados
   - Incluye metadata deportiva cuando aplica

4. **dim_market** - Dimensi√≥n de mercados
   - Mercados de predicci√≥n individuales
   - Outcomes almacenados como JSONB

5. **dim_tag** - Dimensi√≥n de tags con jerarqu√≠a
   - Estructura jer√°rquica multinivel
   - Path para navegaci√≥n de jerarqu√≠a

#### Tabla Puente:

- **bridge_market_tag** - Relaci√≥n many-to-many entre markets y tags

#### Tabla de Hechos:

- **fact_market_metrics** - M√©tricas de mercado
  - Volumen (total, 24h, 1w, 1m, 1y)
  - Liquidez (AMM, CLOB)
  - Precios (desanidados: Yes/No, bid/ask, last trade)
  - Open Interest
  - Cambios de precio (1h, 1d, 1w, 1m, 1y)
  - Engagement (comentarios, tweets)
  - Fees

## üöÄ Instalaci√≥n y Configuraci√≥n

### 1. Instalar dependencias

```bash
pip install psycopg2-binary python-dotenv
```

### 2. Configurar conexi√≥n a NeonDB

Las credenciales est√°n configuradas en `neondb_config.py`:

- **Project ID**: `rapid-shape-37645142`
- **Project Name**: `gabrieldev_RA2`
- **Branch Development**: `br-solitary-paper-aixy2j6f`
- **Branch Production**: `br-cold-tooth-aipr1qpz`

### 3. Crear el esquema en NeonDB

```bash
# En ambiente de desarrollo
python fase2_warehouse/create_schema.py development

# En producci√≥n (cuando est√© listo)
python fase2_warehouse/create_schema.py production
```

Este script:
- Conecta a NeonDB
- Ejecuta el DDL completo
- Crea todas las tablas dimensionales y de hechos
- Crea √≠ndices para optimizaci√≥n de queries

### 4. Ejecutar la carga completa (ETL)

```bash
# En ambiente de desarrollo
python fase2_warehouse/etl_warehouse.py development

# En producci√≥n
python fase2_warehouse/etl_warehouse.py production
```

El ETL ejecuta los siguientes pasos:

1. **Extracci√≥n**: Lee datos de Delta Lake (capa Bronze)
2. **Transformaci√≥n**:
   - Limpieza de datos (manejo de nulos)
   - Normalizaci√≥n de tipos de datos
   - Desanidado de precios (outcomePrices ‚Üí price_yes, price_no)
   - Parseo de campos JSON
3. **Carga**:
   - dim_time (con todas las fechas del rango)
   - dim_series
   - dim_tag (con jerarqu√≠a)
   - dim_event
   - dim_market
   - bridge_market_tag
   - fact_market_metrics

## üìä Caracter√≠sticas del Data Warehouse

### Integridad de Datos

‚úÖ **Limpieza**:
- Manejo de valores NULL
- Conversi√≥n de `nan` a `None`
- Limpieza de strings vac√≠os

‚úÖ **Normalizaci√≥n**:
- Conversi√≥n de tipos de datos apropiados
- Fechas en formato TIMESTAMP
- Num√©ricos en NUMERIC con precisi√≥n adecuada

‚úÖ **Desanidado**:
- Array `outcomePrices` ‚Üí `outcome_price_yes`, `outcome_price_no`
- Array `outcomes` ‚Üí JSONB estructurado
- Campos JSON parseados correctamente

### Optimizaci√≥n para Consultas Anal√≠ticas

‚úÖ **√çndices**:
- √çndices en claves primarias y for√°neas
- √çndices en columnas de filtrado frecuente (fechas, categor√≠as)
- √çndices compuestos para queries comunes

‚úÖ **Particionamiento l√≥gico**:
- Dimensi√≥n de tiempo completa pregenerada
- SCD Type 2 en dimensiones principales

‚úÖ **Star Schema**:
- Queries optimizadas con joins directos
- Tabla puente para relaciones many-to-many
- Desnormalizaci√≥n controlada en tabla de hechos

## üìà Consultas Anal√≠ticas de Ejemplo

### Volumen total por categor√≠a
```sql
SELECT 
    dm.category,
    SUM(fmm.volume) as total_volume,
    COUNT(DISTINCT dm.market_key) as num_markets
FROM fact_market_metrics fmm
JOIN dim_market dm ON fmm.market_key = dm.market_key
WHERE dm.is_current = TRUE
GROUP BY dm.category
ORDER BY total_volume DESC;
```

### Evoluci√≥n de liquidez en el tiempo
```sql
SELECT 
    dt.date_value,
    dt.year,
    dt.month_name,
    SUM(fmm.liquidity) as total_liquidity,
    AVG(fmm.liquidity) as avg_liquidity
FROM fact_market_metrics fmm
JOIN dim_time dt ON fmm.snapshot_date_key = dt.time_key
GROUP BY dt.date_value, dt.year, dt.month_name
ORDER BY dt.date_value;
```

### Top mercados por volumen
```sql
SELECT 
    dm.question,
    dm.category,
    fmm.volume,
    fmm.liquidity,
    fmm.outcome_price_yes,
    fmm.outcome_price_no
FROM fact_market_metrics fmm
JOIN dim_market dm ON fmm.market_key = dm.market_key
JOIN dim_time dt ON fmm.snapshot_date_key = dt.time_key
WHERE dt.date_value = CURRENT_DATE
  AND dm.is_current = TRUE
ORDER BY fmm.volume DESC
LIMIT 10;
```

### An√°lisis por jerarqu√≠a de tags
```sql
SELECT 
    dt.label,
    dt.level,
    dt.path,
    COUNT(DISTINCT bmt.market_key) as num_markets,
    SUM(fmm.volume) as total_volume
FROM dim_tag dt
JOIN bridge_market_tag bmt ON dt.tag_key = bmt.tag_key
JOIN fact_market_metrics fmm ON bmt.market_key = fmm.market_key
WHERE dt.is_current = TRUE
GROUP BY dt.tag_key, dt.label, dt.level, dt.path
ORDER BY dt.level, total_volume DESC;
```

## üîß Mantenimiento

### Actualizaci√≥n incremental

Para actualizaciones futuras, el ETL soporta:
- **UPSERT**: ON CONFLICT DO UPDATE en dimensiones
- **SCD Type 2**: Versionado hist√≥rico en dimensiones principales
- **Idempotencia**: Puede ejecutarse m√∫ltiples veces sin duplicar datos

### Logs

Los logs del ETL se guardan en:
```
logs/etl_warehouse_YYYYMMDD_HHMMSS.log
```

## üìù Notas T√©cnicas

- **PostgreSQL Version**: 17
- **Region**: AWS US East 1
- **Connection Pooling**: Habilitado
- **SSL**: Requerido
- **Transacciones**: Habilitadas (autocommit=False)
- **Batch Insert**: Usando `execute_values` para eficiencia

## ‚úÖ Validaci√≥n

Despu√©s de la carga, validar:

```sql
-- Contar registros en cada tabla
SELECT 'dim_time' as tabla, COUNT(*) as registros FROM dim_time
UNION ALL
SELECT 'dim_series', COUNT(*) FROM dim_series
UNION ALL
SELECT 'dim_tag', COUNT(*) FROM dim_tag
UNION ALL
SELECT 'dim_event', COUNT(*) FROM dim_event
UNION ALL
SELECT 'dim_market', COUNT(*) FROM dim_market
UNION ALL
SELECT 'bridge_market_tag', COUNT(*) FROM bridge_market_tag
UNION ALL
SELECT 'fact_market_metrics', COUNT(*) FROM fact_market_metrics;

-- Verificar integridad referencial
SELECT 
    COUNT(*) as total_facts,
    COUNT(DISTINCT market_key) as unique_markets,
    COUNT(DISTINCT snapshot_date_key) as unique_dates
FROM fact_market_metrics;
```

## üéØ Pr√≥ximos Pasos

1. Ejecutar queries anal√≠ticas
2. Crear vistas materializadas para reports frecuentes
3. Implementar actualizaciones incrementales diarias
4. Configurar monitoring y alertas
5. Documentar KPIs y m√©tricas de negocio
